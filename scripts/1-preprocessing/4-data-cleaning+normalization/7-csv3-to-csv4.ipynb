{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> libraries </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis, skew\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpy import mean, absolute\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> reading ton dataframe </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = f'your-path\\\\TON-IoT\\\\normal-attack\\\\csv-3\\\\ton.csv'\n",
    "ton_df = pd.read_csv(input_path, on_bad_lines=\"error\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> numeric features </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> duration </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change value\n",
    "\n",
    "print(ton_df['duration'].value_counts()['-'])\n",
    "\n",
    "ton_df['duration'] = ton_df['duration'].replace('-', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change datatype\n",
    "\n",
    "ton_df['duration'] = ton_df['duration'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation\n",
    "\n",
    "print(\"old skew is: \", skew(ton_df['duration']))\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "ton_df['duration'] = pt.fit_transform(ton_df[['duration']])\n",
    "\n",
    "print(\"new skew is: \", skew(ton_df['duration']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M-square normalization\n",
    "\n",
    "duration = ton_df['duration']\n",
    "\n",
    "median_duration = np.median(duration)\n",
    "mad_duration = np.median(np.abs(duration - median_duration))\n",
    "\n",
    "print(\"Original Median:\", median_duration)\n",
    "print(\"Original MAD:\", mad_duration)\n",
    "\n",
    "ton_df['duration'] = (duration - median_duration) / mad_duration\n",
    "\n",
    "new_median = np.median(ton_df['duration'])\n",
    "new_mad = np.median(np.abs(ton_df['duration'] - new_median))\n",
    "\n",
    "print(\"New Median after scaling:\", new_median)\n",
    "print(\"New MAD after scaling:\", new_mad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler\n",
    "\n",
    "print(\"original min: \", ton_df['duration'].min())\n",
    "print(\"original max: \", ton_df['duration'].max())\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "ton_df['duration'] = scaler.fit_transform(ton_df[['duration']])\n",
    "\n",
    "print(\"new min: \", ton_df['duration'].min())\n",
    "print(\"new max: \", ton_df['duration'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> src_bytes </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change value\n",
    "\n",
    "print(ton_df['src_bytes'].value_counts()['-'])\n",
    "\n",
    "ton_df['src_bytes'] = ton_df['src_bytes'].replace('-', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change datatype\n",
    "\n",
    "ton_df['src_bytes'] = ton_df['src_bytes'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation\n",
    "\n",
    "print(\"old skew is: \", skew(ton_df['src_bytes']))\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "ton_df['src_bytes'] = pt.fit_transform(ton_df[['src_bytes']])\n",
    "\n",
    "print(\"new skew is: \", skew(ton_df['src_bytes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_bytes = ton_df['src_bytes']\n",
    "\n",
    "median_src_bytes = np.median(src_bytes)\n",
    "mad_src_bytes = np.median(np.abs(src_bytes - median_src_bytes))\n",
    "\n",
    "print(\"Original Median:\", median_src_bytes)\n",
    "print(\"Original MAD:\", mad_src_bytes)\n",
    "\n",
    "ton_df['src_bytes'] = (src_bytes - median_src_bytes) / mad_src_bytes\n",
    "\n",
    "new_median = np.median(ton_df['src_bytes'])\n",
    "new_mad = np.median(np.abs(ton_df['src_bytes'] - new_median))\n",
    "\n",
    "print(\"New Median after scaling:\", new_median)\n",
    "print(\"New MAD after scaling:\", new_mad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler\n",
    "\n",
    "print(\"original min: \", ton_df['src_bytes'].min())\n",
    "print(\"original max: \", ton_df['src_bytes'].max())\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "ton_df['src_bytes'] = scaler.fit_transform(ton_df[['src_bytes']])\n",
    "\n",
    "print(\"new min: \", ton_df['src_bytes'].min())\n",
    "print(\"new max: \", ton_df['src_bytes'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> dst_bytes </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change value\n",
    "\n",
    "print(ton_df['dst_bytes'].value_counts()['-'])\n",
    "\n",
    "ton_df['dst_bytes'] = ton_df['dst_bytes'].replace('-', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change datatype\n",
    "\n",
    "ton_df['dst_bytes'] = ton_df['dst_bytes'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation\n",
    "\n",
    "print(\"old skew is: \", skew(ton_df['dst_bytes']))\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "ton_df['dst_bytes'] = pt.fit_transform(ton_df[['dst_bytes']])\n",
    "\n",
    "print(\"new skew is: \", skew(ton_df['dst_bytes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_bytes = ton_df['dst_bytes']\n",
    "\n",
    "median_dst_bytes = np.median(dst_bytes)\n",
    "mad_dst_bytes = np.median(np.abs(dst_bytes - median_dst_bytes))\n",
    "\n",
    "print(\"Original Median:\", median_dst_bytes)\n",
    "print(\"Original MAD:\", mad_dst_bytes)\n",
    "\n",
    "ton_df['dst_bytes'] = (dst_bytes - median_dst_bytes) / mad_dst_bytes\n",
    "\n",
    "new_median = np.median(ton_df['dst_bytes'])\n",
    "new_mad = np.median(np.abs(ton_df['dst_bytes'] - new_median))\n",
    "\n",
    "print(\"New Median after scaling:\", new_median)\n",
    "print(\"New MAD after scaling:\", new_mad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler\n",
    "\n",
    "print(\"original min: \", ton_df['dst_bytes'].min())\n",
    "print(\"original max: \", ton_df['dst_bytes'].max())\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "ton_df['dst_bytes'] = scaler.fit_transform(ton_df[['dst_bytes']])\n",
    "\n",
    "print(\"new min: \", ton_df['dst_bytes'].min())\n",
    "print(\"new max: \", ton_df['dst_bytes'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> missed_bytes </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation\n",
    "\n",
    "print(\"old skew is: \", skew(ton_df['missed_bytes']))\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "ton_df['missed_bytes'] = pt.fit_transform(ton_df[['missed_bytes']])\n",
    "\n",
    "print(\"new skew is: \", skew(ton_df['missed_bytes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler\n",
    "\n",
    "print(\"original min: \", ton_df['missed_bytes'].min())\n",
    "print(\"original max: \", ton_df['missed_bytes'].max())\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "ton_df['missed_bytes'] = scaler.fit_transform(ton_df[['missed_bytes']])\n",
    "\n",
    "print(\"new min: \", ton_df['missed_bytes'].min())\n",
    "print(\"new max: \", ton_df['missed_bytes'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> src_pkts </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation\n",
    "\n",
    "print(\"old skew is: \", skew(ton_df['src_pkts']))\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "ton_df['src_pkts'] = pt.fit_transform(ton_df[['src_pkts']])\n",
    "\n",
    "print(\"new skew is: \", skew(ton_df['src_pkts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M-square normalization\n",
    "\n",
    "src_pkts = ton_df['src_pkts']\n",
    "\n",
    "median_src_pkts = np.median(src_pkts)\n",
    "mad_src_pkts = np.median(np.abs(src_pkts - median_src_pkts))\n",
    "\n",
    "print(\"Original Median:\", median_src_pkts)\n",
    "print(\"Original MAD:\", mad_src_pkts)\n",
    "\n",
    "ton_df['src_pkts'] = (src_pkts - median_src_pkts) / mad_src_pkts\n",
    "\n",
    "new_median = np.median(ton_df['src_pkts'])\n",
    "new_mad = np.median(np.abs(ton_df['src_pkts'] - new_median))\n",
    "\n",
    "print(\"New Median after scaling:\", new_median)\n",
    "print(\"New MAD after scaling:\", new_mad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler\n",
    "\n",
    "print(\"original min: \", ton_df['src_pkts'].min())\n",
    "print(\"original max: \", ton_df['src_pkts'].max())\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "ton_df['src_pkts'] = scaler.fit_transform(ton_df[['src_pkts']])\n",
    "\n",
    "print(\"new min: \", ton_df['src_pkts'].min())\n",
    "print(\"new max: \", ton_df['src_pkts'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> src_ip_bytes </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation\n",
    "\n",
    "print(\"old skew is: \", skew(ton_df['src_ip_bytes']))\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "ton_df['src_ip_bytes'] = pt.fit_transform(ton_df[['src_ip_bytes']])\n",
    "\n",
    "print(\"new skew is: \", skew(ton_df['src_ip_bytes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M-square normalization\n",
    "\n",
    "src_ip_bytes = ton_df['src_ip_bytes']\n",
    "\n",
    "median_src_ip_bytes = np.median(src_ip_bytes)\n",
    "mad_src_ip_bytes = np.median(np.abs(src_ip_bytes - median_src_ip_bytes))\n",
    "\n",
    "print(\"Original Median:\", median_src_ip_bytes)\n",
    "print(\"Original MAD:\", mad_src_ip_bytes)\n",
    "\n",
    "ton_df['src_ip_bytes'] = (src_ip_bytes - median_src_ip_bytes) / mad_src_ip_bytes\n",
    "\n",
    "new_median = np.median(ton_df['src_ip_bytes'])\n",
    "new_mad = np.median(np.abs(ton_df['src_ip_bytes'] - new_median))\n",
    "\n",
    "print(\"New Median after scaling:\", new_median)\n",
    "print(\"New MAD after scaling:\", new_mad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler\n",
    "\n",
    "print(\"original min: \", ton_df['src_ip_bytes'].min())\n",
    "print(\"original max: \", ton_df['src_ip_bytes'].max())\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "ton_df['src_ip_bytes'] = scaler.fit_transform(ton_df[['src_ip_bytes']])\n",
    "\n",
    "print(\"new min: \", ton_df['src_ip_bytes'].min())\n",
    "print(\"new max: \", ton_df['src_ip_bytes'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> dst_pkts </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation\n",
    "\n",
    "print(\"old skew is: \", skew(ton_df['dst_pkts']))\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "ton_df['dst_pkts'] = pt.fit_transform(ton_df[['dst_pkts']])\n",
    "\n",
    "print(\"new skew is: \", skew(ton_df['dst_pkts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M-square normalization\n",
    "\n",
    "dst_pkts = ton_df['dst_pkts']\n",
    "\n",
    "median_dst_pkts = np.median(dst_pkts)\n",
    "mad_dst_pkts = np.median(np.abs(dst_pkts - median_dst_pkts))\n",
    "\n",
    "print(\"Original Median:\", median_dst_pkts)\n",
    "print(\"Original MAD:\", mad_dst_pkts)\n",
    "\n",
    "ton_df['dst_pkts'] = (dst_pkts - median_dst_pkts) / mad_dst_pkts\n",
    "\n",
    "new_median = np.median(ton_df['dst_pkts'])\n",
    "new_mad = np.median(np.abs(ton_df['dst_pkts'] - new_median))\n",
    "\n",
    "print(\"New Median after scaling:\", new_median)\n",
    "print(\"New MAD after scaling:\", new_mad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler\n",
    "\n",
    "print(\"original min: \", ton_df['dst_pkts'].min())\n",
    "print(\"original max: \", ton_df['dst_pkts'].max())\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "ton_df['dst_pkts'] = scaler.fit_transform(ton_df[['dst_pkts']])\n",
    "\n",
    "print(\"new min: \", ton_df['dst_pkts'].min())\n",
    "print(\"new max: \", ton_df['dst_pkts'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> dst_ip_bytes </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation\n",
    "\n",
    "print(\"old skew is: \", skew(ton_df['dst_ip_bytes']))\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "ton_df['dst_ip_bytes'] = pt.fit_transform(ton_df[['dst_ip_bytes']])\n",
    "\n",
    "print(\"new skew is: \", skew(ton_df['dst_ip_bytes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M-square normalization\n",
    "\n",
    "dst_ip_bytes = ton_df['dst_ip_bytes']\n",
    "\n",
    "median_dst_ip_bytes = np.median(dst_ip_bytes)\n",
    "mad_dst_ip_bytes = np.median(np.abs(dst_ip_bytes - median_dst_ip_bytes))\n",
    "\n",
    "print(\"Original Median:\", median_dst_ip_bytes)\n",
    "print(\"Original MAD:\", mad_dst_ip_bytes)\n",
    "\n",
    "ton_df['dst_ip_bytes'] = (dst_ip_bytes - median_dst_ip_bytes) / mad_dst_ip_bytes\n",
    "\n",
    "new_median = np.median(ton_df['dst_ip_bytes'])\n",
    "new_mad = np.median(np.abs(ton_df['dst_ip_bytes'] - new_median))\n",
    "\n",
    "print(\"New Median after scaling:\", new_median)\n",
    "print(\"New MAD after scaling:\", new_mad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler\n",
    "\n",
    "print(\"original min: \", ton_df['dst_ip_bytes'].min())\n",
    "print(\"original max: \", ton_df['dst_ip_bytes'].max())\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "ton_df['dst_ip_bytes'] = scaler.fit_transform(ton_df[['dst_ip_bytes']])\n",
    "\n",
    "print(\"new min: \", ton_df['dst_ip_bytes'].min())\n",
    "print(\"new max: \", ton_df['dst_ip_bytes'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> http_trans_depth </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation\n",
    "\n",
    "ton_df.fillna({'http_trans_depth': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation\n",
    "\n",
    "print(\"old skew is: \", skew(ton_df['http_trans_depth']))\n",
    "pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "ton_df['http_trans_depth'] = pt.fit_transform(ton_df[['http_trans_depth']])\n",
    "print(\"new skew is: \", skew(ton_df['http_trans_depth']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> http_request_body_len </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation\n",
    "\n",
    "ton_df.fillna({'http_request_body_len': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation\n",
    "\n",
    "print(\"old skew is: \", skew(ton_df['http_request_body_len']))\n",
    "pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "ton_df['http_request_body_len'] = pt.fit_transform(ton_df[['http_request_body_len']])\n",
    "print(\"new skew is: \", skew(ton_df['http_request_body_len']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> http_response_body_len </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation\n",
    "\n",
    "ton_df.fillna({'http_response_body_len': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation\n",
    "\n",
    "print(\"old skew is: \", skew(ton_df['http_response_body_len']))\n",
    "pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "ton_df['http_response_body_len'] = pt.fit_transform(ton_df[['http_response_body_len']])\n",
    "print(\"new skew is: \", skew(ton_df['http_response_body_len']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler\n",
    "\n",
    "print(\"original min: \", ton_df['http_response_body_len'].min())\n",
    "print(\"original max: \", ton_df['http_response_body_len'].max())\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "ton_df['http_response_body_len'] = scaler.fit_transform(ton_df[['http_response_body_len']])\n",
    "\n",
    "print(\"new min: \", ton_df['http_response_body_len'].min())\n",
    "print(\"new max: \", ton_df['http_response_body_len'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> string features </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> proto </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ton_df = pd.get_dummies(ton_df, columns=['proto'])\n",
    "#\n",
    "#ton_df['proto_tcp'] = ton_df['proto_tcp'].astype(int)\n",
    "#ton_df['proto_icmp'] = ton_df['proto_icmp'].astype(int)\n",
    "#ton_df['proto_udp'] = ton_df['proto_udp'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "ton_df['proto'] = le.fit_transform(ton_df['proto'])\n",
    "\n",
    "proto_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "file_path = r'your-path\\\\TON-IoT\\\\normal-attack\\\\csv-3\\\\proto_mapping.txt'\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    for proto, encoded_value in proto_mapping.items():\n",
    "        f.write(f\"{proto}: {encoded_value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> service </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change - value\n",
    "\n",
    "ton_df['service'] = ton_df['service'].replace('-', 'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "ton_df['service'] = le.fit_transform(ton_df['service'])\n",
    "\n",
    "service_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "file_path = r'your-path\\\\TON-IoT\\\\normal-attack\\\\csv-3\\\\service_mapping.txt'\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    for service, encoded_value in service_mapping.items():\n",
    "        f.write(f\"{service}: {encoded_value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> conn_state </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "ton_df['conn_state'] = le.fit_transform(ton_df['conn_state'])\n",
    "\n",
    "conn_state_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "file_path = r'your-path\\\\TON-IoT\\\\normal-attack\\\\csv-3\\\\conn_state_mapping.txt'\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    for conn_state, encoded_value in conn_state_mapping.items():\n",
    "        f.write(f\"{conn_state}: {encoded_value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> dns_query </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not ...\n",
    "\n",
    "ton_df.loc[ton_df['service'] != 2, 'dns_query'] = 0 # 0 means the service is not dns\n",
    "\n",
    "print(\"number of null values is: \", ton_df['dns_query'].isnull().sum())\n",
    "\n",
    "ton_df.fillna({'dns_query': 1}, inplace=True)       # 1 means query is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['dns_query'][(ton_df['dns_query'] != 0)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 1\n",
    "ton_df.loc[(ton_df['dns_query'] != 0), 'dns_query'] = encoded_values\n",
    "ton_df['dns_query'] = ton_df['dns_query'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> dns_qclass </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not ...\n",
    "\n",
    "ton_df.loc[ton_df['service'] != 2, 'dns_qclass'] = 0 # 0 means the service is not dns\n",
    "\n",
    "print(\"number of null values is: \", ton_df['dns_qclass'].isnull().sum())\n",
    "\n",
    "ton_df.fillna({'dns_qclass': 1}, inplace=True)       # 1 means qclass is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['dns_qclass'][(ton_df['dns_qclass'] != 0)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 1\n",
    "ton_df.loc[(ton_df['dns_qclass'] != 0), 'dns_qclass'] = encoded_values\n",
    "ton_df['dns_qclass'] = ton_df['dns_qclass'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> dns_qtype </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not ...\n",
    "\n",
    "ton_df.loc[ton_df['service'] != 2, 'dns_qtype'] = 0 # 0 means the service is not DNS\n",
    "\n",
    "print(\"number of null values is: \", ton_df['dns_qtype'].isnull().sum())\n",
    "\n",
    "ton_df.fillna({'dns_qtype': 1}, inplace=True)       # 1 means query type is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['dns_qtype'][(ton_df['dns_qtype'] != 0) & (ton_df['dns_qtype'] != 1)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 2\n",
    "ton_df.loc[(ton_df['dns_qtype'] != 0) & (ton_df['dns_qtype'] != 1), 'dns_qtype'] = encoded_values\n",
    "ton_df['dns_qtype'] = ton_df['dns_qtype'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> dns_rcode </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not ...\n",
    "\n",
    "ton_df.loc[ton_df['service'] != 2, 'dns_rcode'] = 0 # 0 means the service is not DNS\n",
    "\n",
    "print(\"number of null values is: \", ton_df['dns_rcode'].isnull().sum())\n",
    "\n",
    "ton_df.fillna({'dns_rcode': 1}, inplace=True)       # 1 means dns_rcode is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['dns_rcode'][(ton_df['dns_rcode'] != 0) & (ton_df['dns_rcode'] != 1)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 2\n",
    "ton_df.loc[(ton_df['dns_rcode'] != 0) & (ton_df['dns_rcode'] != 1), 'dns_rcode'] = encoded_values\n",
    "ton_df['dns_rcode'] = ton_df['dns_rcode'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> dns_AA </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not ... \n",
    "\n",
    "ton_df.loc[ton_df['service'] != 2, 'dns_AA'] = 0 # 0 means the service is not DNS\n",
    "\n",
    "print(\"number of null values is: \", ton_df['dns_AA'].isnull().sum())\n",
    "\n",
    "ton_df.fillna({'dns_AA': 1}, inplace=True)       # 1 means dns_AA is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['dns_AA'][(ton_df['dns_AA'] != 0) & (ton_df['dns_AA'] != 1)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 2\n",
    "ton_df.loc[(ton_df['dns_AA'] != 0) & (ton_df['dns_AA'] != 1), 'dns_AA'] = encoded_values\n",
    "ton_df['dns_AA'] = ton_df['dns_AA'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> dns_RD </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not ...\n",
    "\n",
    "ton_df.loc[ton_df['service'] != 2, 'dns_RD'] = 0 # 0 means the service is not DNS\n",
    "\n",
    "print(\"number of null values is: \", ton_df['dns_RD'].isnull().sum())\n",
    "\n",
    "ton_df.fillna({'dns_RD': 1}, inplace=True)       # 1 means dns_RD is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['dns_RD'][(ton_df['dns_RD'] != 0) & (ton_df['dns_RD'] != 1)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 2\n",
    "ton_df.loc[(ton_df['dns_RD'] != 0) & (ton_df['dns_RD'] != 1), 'dns_RD'] = encoded_values\n",
    "ton_df['dns_RD'] = ton_df['dns_RD'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> dns_RA </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not ...\n",
    "\n",
    "ton_df.loc[ton_df['service'] != 2, 'dns_RA'] = 0 # 0 means the service is not DNS\n",
    "\n",
    "print(\"number of null values is: \", ton_df['dns_RA'].isnull().sum())\n",
    "\n",
    "ton_df.fillna({'dns_RA': 1}, inplace=True)       # 1 means dns_RA is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['dns_RA'][(ton_df['dns_RA'] != 0) & (ton_df['dns_RA'] != 1)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 2\n",
    "ton_df.loc[(ton_df['dns_RA'] != 0) & (ton_df['dns_RA'] != 1), 'dns_RA'] = encoded_values\n",
    "ton_df['dns_RA'] = ton_df['dns_RA'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> dns_rejected </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not ...\n",
    "\n",
    "ton_df.loc[ton_df['service'] != 2, 'dns_rejected'] = 0 # 0 means the service is not DNS\n",
    "\n",
    "print(\"number of null values is: \", ton_df['dns_rejected'].isnull().sum())\n",
    "\n",
    "ton_df.fillna({'dns_rejected': 1}, inplace=True)       # 1 means dns_rejected is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['dns_rejected'][(ton_df['dns_rejected'] != 0) & (ton_df['dns_rejected'] != 1)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 2\n",
    "ton_df.loc[(ton_df['dns_rejected'] != 0) & (ton_df['dns_rejected'] != 1), 'dns_rejected'] = encoded_values\n",
    "ton_df['dns_rejected'] = ton_df['dns_rejected'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> http_method </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not http\n",
    "\n",
    "ton_df.loc[ton_df['service'] != 9, 'http_method'] = 0 # 0 means the service is not HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['http_method'][(ton_df['http_method'] != 0)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 1\n",
    "ton_df.loc[(ton_df['http_method'] != 0), 'http_method'] = encoded_values\n",
    "ton_df['http_method'] = ton_df['http_method'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> http_uri </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not http\n",
    "\n",
    "ton_df.loc[ton_df['service'] != 9, 'http_uri'] = 0 # 0 means the service is not HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['http_uri'][(ton_df['http_uri'] != 0)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 1\n",
    "ton_df.loc[(ton_df['http_uri'] != 0), 'http_uri'] = encoded_values\n",
    "ton_df['http_uri'] = ton_df['http_uri'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> http_referrer </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not http\n",
    "\n",
    "ton_df.loc[ton_df['service'] != 9, 'http_referrer'] = 0 # 0 means the service is not HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['http_referrer'][(ton_df['http_referrer'] != 0)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 1\n",
    "ton_df.loc[(ton_df['http_referrer'] != 0), 'http_referrer'] = encoded_values\n",
    "ton_df['http_referrer'] = ton_df['http_referrer'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> http_version </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not http\n",
    "\n",
    "ton_df.loc[ton_df['service'] != 9, 'http_version'] = 0 # 0 means the service is not HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['http_version'][(ton_df['http_version'] != 0)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 1\n",
    "ton_df.loc[(ton_df['http_version'] != 0), 'http_version'] = encoded_values\n",
    "ton_df['http_version'] = ton_df['http_version'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> http_status_code </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not http\n",
    "\n",
    "ton_df.loc[ton_df['service'] != 9, 'http_status_code'] = 0 # 0 means the service is not HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['http_status_code'][(ton_df['http_status_code'] != 0)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 1\n",
    "ton_df.loc[(ton_df['http_status_code'] != 0), 'http_status_code'] = encoded_values\n",
    "ton_df['http_status_code'] = ton_df['http_status_code'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> http_user_agent </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not http\n",
    "\n",
    "ton_df.loc[ton_df['service'] != 9, 'http_user_agent'] = 0 # 0 means the service is not HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['http_user_agent'][(ton_df['http_user_agent'] != 0)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 1\n",
    "ton_df.loc[(ton_df['http_user_agent'] != 0), 'http_user_agent'] = encoded_values\n",
    "ton_df['http_user_agent'] = ton_df['http_user_agent'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> http_orig_mime_types </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not http\n",
    "\n",
    "ton_df.loc[ton_df['service'] != 9, 'http_orig_mime_types'] = 0 # 0 means the service is not HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['http_orig_mime_types'][(ton_df['http_orig_mime_types'] != 0)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 1\n",
    "ton_df.loc[(ton_df['http_orig_mime_types'] != 0), 'http_orig_mime_types'] = encoded_values\n",
    "ton_df['http_orig_mime_types'] = ton_df['http_orig_mime_types'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> http_resp_mime_types </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not http\n",
    "\n",
    "ton_df.loc[ton_df['service'] != 9, 'http_resp_mime_types'] = 0 # 0 means the service is not HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['http_resp_mime_types'][(ton_df['http_resp_mime_types'] != 0)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 1\n",
    "ton_df.loc[(ton_df['http_resp_mime_types'] != 0), 'http_resp_mime_types'] = encoded_values\n",
    "ton_df['http_resp_mime_types'] = ton_df['http_resp_mime_types'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> ssl_version </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not ssl\n",
    "\n",
    "ton_df.fillna({'ssl_version': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['ssl_version'][(ton_df['ssl_version'] != 0)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 1\n",
    "ton_df.loc[(ton_df['ssl_version'] != 0) & (ton_df['ssl_version'] != 1), 'ssl_version'] = encoded_values\n",
    "ton_df['ssl_version'] = ton_df['ssl_version'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> ssl_cipher </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not ssl\n",
    "\n",
    "ton_df.fillna({'ssl_cipher': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['ssl_cipher'][(ton_df['ssl_cipher'] != 0)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 1\n",
    "ton_df.loc[(ton_df['ssl_cipher'] != 0) & (ton_df['ssl_cipher'] != 1), 'ssl_cipher'] = encoded_values\n",
    "ton_df['ssl_cipher'] = ton_df['ssl_cipher'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> ssl_resumed </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not ssl\n",
    "\n",
    "ton_df.fillna({'ssl_resumed': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['ssl_resumed'][(ton_df['ssl_resumed'] != 0)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 1\n",
    "ton_df.loc[(ton_df['ssl_resumed'] != 0) & (ton_df['ssl_resumed'] != 1), 'ssl_resumed'] = encoded_values\n",
    "ton_df['ssl_resumed'] = ton_df['ssl_resumed'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> ssl_established </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not ssl\n",
    "\n",
    "ton_df.fillna({'ssl_established': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['ssl_established'][(ton_df['ssl_established'] != 0)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 1\n",
    "ton_df.loc[(ton_df['ssl_established'] != 0) & (ton_df['ssl_established'] != 1), 'ssl_established'] = encoded_values\n",
    "ton_df['ssl_established'] = ton_df['ssl_established'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> ssl_subject </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not ssl\n",
    "\n",
    "ton_df.fillna({'ssl_subject': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['ssl_subject'][(ton_df['ssl_subject'] != 0)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 1\n",
    "ton_df.loc[(ton_df['ssl_subject'] != 0) & (ton_df['ssl_subject'] != 1), 'ssl_subject'] = encoded_values\n",
    "ton_df['ssl_subject'] = ton_df['ssl_subject'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> ssl_issuer </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not ssl\n",
    "\n",
    "ton_df.fillna({'ssl_issuer': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['ssl_issuer'][(ton_df['ssl_issuer'] != 0)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 1\n",
    "ton_df.loc[(ton_df['ssl_issuer'] != 0) & (ton_df['ssl_issuer'] != 1), 'ssl_issuer'] = encoded_values\n",
    "ton_df['ssl_issuer'] = ton_df['ssl_issuer'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> weird_name </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "ton_df.fillna({'weird_name': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['weird_name'][(ton_df['weird_name'] != 0)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 1\n",
    "ton_df.loc[(ton_df['weird_name'] != 0) & (ton_df['weird_name'] != 1), 'weird_name'] = encoded_values\n",
    "ton_df['weird_name'] = ton_df['weird_name'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> weird_addl </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "ton_df.fillna({'weird_addl': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "ton_df['weird_addl'] = ton_df['weird_addl'].replace('-', 'nothing')\n",
    "le = LabelEncoder()\n",
    "non_zero_values = ton_df['weird_addl'][(ton_df['weird_addl'] != 0)]\n",
    "non_zero_values = non_zero_values.astype(str)\n",
    "encoded_values = le.fit_transform(non_zero_values)\n",
    "encoded_values = encoded_values + 1\n",
    "ton_df.loc[(ton_df['weird_addl'] != 0) & (ton_df['weird_addl'] != 1), 'weird_addl'] = encoded_values\n",
    "ton_df['weird_addl'] = ton_df['weird_addl'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> weird_notice </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "ton_df.fillna({'weird_notice': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ton_df['weird_notice'] = ton_df['weird_notice'].replace('F', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> save dataframe </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ton_df.to_csv(\"your-path\\\\TON-IoT\\\\normal-attack\\\\csv-4\\\\ton.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
